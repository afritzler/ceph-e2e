name: Run e2e tests

on:
  pull_request:
    types: [labeled, synchronize, reopened]
    paths-ignore:
      - 'docs/**'

jobs:
  e2e-tests:
    runs-on: macos-13
    if: contains(github.event.pull_request.labels.*.name, 'e2e-tests')

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Checkout code
        uses: actions/checkout@v2

      - uses: actions/setup-go@v4
        with:
          go-version-file: 'go.mod'

      - uses: azure/setup-kubectl@v3

      - uses: azure/setup-helm@v3
        with:
          version: 'v3.12.2'

      - name: Install Homebrew
        run: /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

      - name: Install Homebrew dependencies
        run: |
          brew update
          brew install --cask macfuse
          brew install qemu doxygen python

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install Cython==0.29.36

      - name: Cache ceph-client formula
        id: cache-wget
        uses: actions/cache@v2
        with:
          path: /usr/local/Cellar/ceph-client
          key: ceph-client-${{ runner.os }}-${{ steps.get-date.outputs.date }}
          restore-keys: |
            ceph-client-${{ runner.os }}-

      - name: Install ceph-client if not cached
        if: steps.cache-ceph-client.outputs.cache-hit != 'true'
        run: |
          sudo chown -R ${USER}:staff /usr/local/opt/
          brew tap afritzler/ceph-client
          brew install ceph-client

      - name: Get current date
        id: get-date
        run: echo "::set-output name=date::$(date +'%Y-%m-%d')"

      - name: Start minikube
        uses: medyagh/setup-minikube@latest
        id: minikube
        with:
          cpus: 2
          memory: 6000m
          cni: bridge
          start-args: '--disk-size=10g --extra-disks 1 --driver qemu'

      - name: Add Rook repository
        run: helm repo add rook-release https://charts.rook.io/release

      - name: Install Rook Operator
        run: helm install --create-namespace --namespace rook-ceph rook-ceph rook-release/rook-ceph --set csi.enableRbdDriver=false --set csi.enableCephfsDriver=false

      - name: Verify Rook CRDs installation
        run: |
          end=$((SECONDS+20))  # 20 seconds timeout
          while [ $SECONDS -lt $end ]; do
            if kubectl get crds | grep -q 'cephclusters.ceph.rook.io'; then
              echo "Rook CRDs have been installed!"
              exit 0
            fi
            echo "Waiting for Rook CRDs to be installed..."
            sleep 10
          done
          
          echo "Timeout waiting for Rook CRDs!"
          exit 1

      - name: Apply CephCluster configuration
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: rook-config-override
            namespace: rook-ceph
          data:
            config: |
              [global]
              osd_pool_default_size = 1
              mon_warn_on_pool_no_redundancy = false
              bdev_flock_retry = 20
              bluefs_buffered_io = false
              mon_data_avail_warn = 10
          ---
          apiVersion: ceph.rook.io/v1
          kind: CephCluster
          metadata:
            name: my-cluster
            namespace: rook-ceph
          spec:
            cephVersion:
              allowUnsupported: true
              image: quay.io/ceph/ceph:v17
            cleanupPolicy:
              sanitizeDisks: {}
            crashCollector:
              disable: true
            dashboard:
              enabled: true
            dataDirHostPath: /var/lib/rook
            disruptionManagement:
              managePodBudgets: true
            external: {}
            healthCheck:
              daemonHealth:
                mon:
                  interval: 45s
                  timeout: 600s
                osd: {}
                status: {}
            logCollector: {}
            mgr:
              allowMultiplePerNode: true
              count: 1
            mon:
              allowMultiplePerNode: true
              count: 1
            monitoring: {}
            network:
              hostNetwork: true
            priorityClassNames:
              all: system-node-critical
              mgr: system-cluster-critical
            security:
              kms: {}
            storage:
              useAllDevices: true
              useAllNodes: true
          ---
          apiVersion: ceph.rook.io/v1
          kind: CephBlockPool
          metadata:
            name: cephlet-pool
            namespace: rook-ceph
          spec:
            name: .mgr
            erasureCoded:
              codingChunks: 0
              dataChunks: 0
            replicated:
              size: 1
              requireSafeReplicaSize: false
          ---
          apiVersion: ceph.rook.io/v1
          kind: CephClient
          metadata:
            name: cephlet-pool
            namespace: rook-ceph
          spec:
            caps:
              mgr: profile rbd pool=cephlet-pool
              mon: profile rbd
              osd: profile rbd pool=cephlet-pool
          EOF

      - name: Wait for CephCluster to be healthy or warning
        run: |
          echo "Waiting for CephCluster to be healthy or in warning status..."
          while true; do
            kubectl -n rook-ceph get pods 
            HEALTH_STATUS=$(kubectl -n rook-ceph get cephcluster -o jsonpath='{.items[0].status.ceph.health}')
            echo "CephCluster health status: $HEALTH_STATUS"
            if [[ "$HEALTH_STATUS" == "HEALTH_OK" || "$HEALTH_STATUS" == "HEALTH_WARN" ]]; then
              kubectl -n rook-ceph get pods
              kubectl -n rook-ceph logs -l app=rook-ceph-osd-prepare
              break
            fi
            sleep 30
          done
          echo "CephCluster is in acceptable state!"

      - name: Get operator logs
        run: |
          echo "Waiting for CephBlockPool to become ready ..."
          end=$((SECONDS+20))  # 20 seconds timeout
          while [ $SECONDS -lt $end ]; do
            POLL_STATUS=$(kubectl -n rook-ceph get cephblockpool cephlet-pool -o jsonpath='{.status.phase}')
            if [[ "$POLL_STATUS" == "Ready" ]]; then
              break
            fi
            kubectl -n rook-ceph logs -l app=rook-ceph-operator
            sleep 30
          done
          echo "CephBlockPool is in ready state!"

#      - name: Wait for CephCluster to become ready
#        run: |
#          kubectl wait --for=condition=ready --timeout=30s pod -n rook-ceph -l app=rook-ceph-mon
#          kubectl wait --for=condition=ready --timeout=30s cephcluster -n rook-ceph my-cluster
#          kubectl -n rook-ceph logs -l app=rook-ceph-operator
#          kubectl wait --for=condition=ready --timeout=1200s cephblockpool -n rook-ceph cephlet-pool

      - name: Set Environment Variables
        run: |
          echo "CEPH_USERNAME=admin" >> $GITHUB_ENV
          echo "CEPH_POOLNAME=cephlet-pool" >> $GITHUB_ENV
          echo "CEPH_CLIENTNAME=client.cephlet-pool" >> $GITHUB_ENV
          keyring=$(kubectl -n rook-ceph get secret rook-ceph-admin-keyring -o jsonpath={.data.keyring})
          echo "CEPH_KEY=$keyring" >> $GITHUB_ENV
          mon=$(kubectl -n rook-ceph get cm rook-ceph-mon-endpoints -o jsonpath={.data.data})
          echo "CEPH_MONITORS=$(echo $mon | sed 's/^[^0-9[]*//')" >> $GITHUB_ENV

      - name: Run tests
        run: E2E_TESTS=true CGO=1 go test ./...
