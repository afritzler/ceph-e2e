name: Run e2e tests

on:
  pull_request:
    types: [labeled, synchronize, reopened]
    paths-ignore:
      - 'docs/**'

jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'e2e-tests')

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - uses: actions/setup-go@v4
        with:
          go-version-file: 'go.mod'

      - uses: azure/setup-kubectl@v3

      - uses: azure/setup-helm@v3
        with:
          version: 'v3.12.2'

      - name: Update APT and install ceph libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcephfs-dev librbd-dev librados-dev

      - name: Create loop back device
        run: |
          sudo dd if=/dev/zero of=/tmp/foo bs=1 count=0 seek=5G
          sudo losetup -fP /tmp/foo

      - name: Start minikube
        uses: medyagh/setup-minikube@latest
        id: minikube
        with:
          driver: none
          start-args: '--mount --mount-string="/dev/loop0:/dev/loop0"'

      - name: Add Rook repository
        run: helm repo add rook-release https://charts.rook.io/release

      - name: Install Rook Operator
        run: helm install --create-namespace --namespace rook-ceph rook-ceph rook-release/rook-ceph --set csi.enableRbdDriver=false --set csi.enableCephfsDriver=false

      - name: Verify Rook CRDs installation
        run: |
          end=$((SECONDS+20))  # 20 seconds timeout
          while [ $SECONDS -lt $end ]; do
            if kubectl get crds | grep -q 'cephclusters.ceph.rook.io'; then
              echo "Rook CRDs have been installed!"
              exit 0
            fi
            echo "Waiting for Rook CRDs to be installed..."
            sleep 10
          done
          
          echo "Timeout waiting for Rook CRDs!"
          exit 1

      - name: Apply CephCluster configuration
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: rook-config-override
            namespace: rook-ceph
          data:
            config: |
              [global]
              osd_pool_default_size = 1
              mon_warn_on_pool_no_redundancy = false
              bdev_flock_retry = 20
              bluefs_buffered_io = false
              mon_data_avail_warn = 10
          ---
          apiVersion: ceph.rook.io/v1
          kind: CephCluster
          metadata:
            name: rook-ceph
            namespace: rook-ceph # namespace:cluster
          spec:
            cephVersion:
              image: quay.io/ceph/ceph:v17.2.6
            dataDirHostPath: /var/lib/rook
            network:
              provider: host
            mon:
              count: 1
            storage:
              useAllNodes: true
              useAllDevices: false
              deviceFilter: "loop0"
          ---
          apiVersion: ceph.rook.io/v1
          kind: CephBlockPool
          metadata:
            name: cephlet-pool
            namespace: rook-ceph
          spec:
            erasureCoded:
              codingChunks: 0
              dataChunks: 0
            replicated:
              size: 1
              requireSafeReplicaSize: false
          ---
          apiVersion: ceph.rook.io/v1
          kind: CephClient
          metadata:
            name: cephlet-pool
            namespace: rook-ceph
          spec:
            caps:
              mgr: profile rbd pool=cephlet-pool
              mon: profile rbd
              osd: profile rbd pool=cephlet-pool
          EOF

      - name: Wait for CephCluster to be healthy or warning
        run: |
          echo "Waiting for CephCluster to be healthy or in warning status..."
          while true; do
            kubectl -n rook-ceph get pods 
            kubectl -n rook-ceph get pv,pvc
            HEALTH_STATUS=$(kubectl -n rook-ceph get cephcluster -o jsonpath='{.items[0].status.ceph.health}')
            echo "CephCluster health status: $HEALTH_STATUS"
            if [[ "$HEALTH_STATUS" == "HEALTH_OK" || "$HEALTH_STATUS" == "HEALTH_WARN" ]]; then
              kubectl -n rook-ceph get pods
              kubectl -n rook-ceph logs -l app=rook-ceph-osd-prepare
              break
            fi
            sleep 10
          done
          echo "CephCluster is in acceptable state!"

      - name: Wait for CephBlockPool to be ready
        run: |
          echo "Waiting for CephBlockPool to become ready ..."
          kubectl get node -o wide
          hostname -I | awk '{print $1}'
          end=$((SECONDS+600))  # 10 mins timeout
          while [ $SECONDS -lt $end ]; do
            POLL_STATUS=$(kubectl -n rook-ceph get cephblockpool cephlet-pool -o jsonpath='{.status.phase}')
            if [[ "$POLL_STATUS" == "Ready" ]]; then
              break
            fi
            kubectl -n rook-ceph logs -l app=rook-ceph-operator
            kubectl -n rook-ceph get pods
            sleep 10
          done
          kubectl -n rook-ceph get cephblockpool,cephcluster,pod
          echo "CephBlockPool is in ready state!"

      - name: Set Environment Variables
        run: |
          echo "CEPH_USERNAME=admin" >> $GITHUB_ENV
          echo "CEPH_POOLNAME=cephlet-pool" >> $GITHUB_ENV
          echo "CEPH_CLIENTNAME=client.cephlet-pool" >> $GITHUB_ENV
          keyring=$(kubectl -n rook-ceph get secret rook-ceph-admin-keyring -o jsonpath={.data.keyring})
          echo $keyring | base64 -d > $PWD/keyring
          echo "CEPH_KEYRING_FILENAME=$PWD/keyring" >> $GITHUB_ENV
          mon=$(kubectl -n rook-ceph get cm rook-ceph-mon-endpoints -o jsonpath={.data.data})
          echo "CEPH_MONITORS=$(echo $mon | sed 's/^[^0-9[]*//')" >> $GITHUB_ENV

      - name: Run tests
        run: E2E_TESTS=true CGO=1 go test ./...
